{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f8675e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a4f33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.5 | packaged by Anaconda, Inc. | (main, Jun 12 2025, 11:23:37) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import datetime as dt\n",
    "import pytz\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# VERBOSE: print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Configuration\n",
    "TIMEZONE = pytz.timezone(\"Africa/Dar_es_Salaam\")\n",
    "\n",
    "# Dataset configuration - using simple relative paths\n",
    "DATA_FOLDER = Path(\"data/omnisense\")\n",
    "EXTERNAL_TEMP_FILE = DATA_FOLDER / \"open-meteo-7.07S39.30E81m.csv\"\n",
    "\n",
    "USECOLS = [1, 2, 3]  # B, C, D columns\n",
    "\n",
    "# Logger name mapping\n",
    "LOGGER_NAMES = {\n",
    "    \"861011\": \"External Ambient (861011)\",\n",
    "    \"780981\": \"Living Room (780981)\",\n",
    "    \"639148\": \"Study (639148)\",\n",
    "    \"759522\": \"Bed 1 (759522)\",\n",
    "    \"759521\": \"Bed 2 (759521)\",\n",
    "    \"759209\": \"Bed 3 (759209)\",\n",
    "    \"759492\": \"Bed 4 (759492)\",\n",
    "    \"861968\": \"Living Room (below metal) (861968)\",\n",
    "    \"759493\": \"Living Room (above ceiling) (759493)\",\n",
    "    \"759498\": \"Dauda's House (759498)\",\n",
    "    \"861004\": \"Bed 3 (above ceiling) (861004)\",\n",
    "    \"861034\": \"Bed 3 (above ceiling) (861034)\",\n",
    "    \"759519\": \"Bed 4 (below metal) (759519)\",\n",
    "    \"759489\": \"Bed 4 (above ceiling) (759489)\",\n",
    "    \"govee\": \"Govee Smart Hygrometer\",\n",
    "    \"External (Open-Meteo)\": \"External Temperature\"\n",
    "}\n",
    "\n",
    "def get_season_lines(start_date, end_date):\n",
    "    \"\"\"Generate vertical lines for season boundaries.\"\"\"\n",
    "    lines = []\n",
    "    start_year = start_date.year\n",
    "    end_year = end_date.year\n",
    "    \n",
    "    # Season dates: 01/06, 01/11, 01/01, 01/03 (dd/mm) with names\n",
    "    season_info = [\n",
    "        (6, 1, \"June Dry Season (Kiangazi)\"),\n",
    "        (11, 1, \"Short Rains (Vuli)\"),\n",
    "        (1, 1, \"January Dry Season (Kiangazi)\"),\n",
    "        (3, 1, \"Long Rains (Masika)\")\n",
    "    ]\n",
    "    \n",
    "    for year in range(start_year - 1, end_year + 2):  # Extended range to ensure coverage\n",
    "        for month, day, name in season_info:\n",
    "            season_timestamp = pd.Timestamp(year=year, month=month, day=day, tz=TIMEZONE)\n",
    "            if start_date <= season_timestamp <= end_date:\n",
    "                lines.append((season_timestamp, name))\n",
    "    \n",
    "    return sorted(lines, key=lambda x: x[0])\n",
    "\n",
    "\n",
    "def get_season_for_date(date):\n",
    "    \"\"\"Get the season name for a given date.\"\"\"\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    \n",
    "    # Define season boundaries (month, day)\n",
    "    if (month == 6 and day >= 1) or (month > 6 and month < 11):\n",
    "        return \"June Dry Season (Kiangazi)\"\n",
    "    elif (month == 11 and day >= 1) or (month == 12):\n",
    "        return \"Short Rains (Vuli)\"\n",
    "    elif (month == 1 and day >= 1) or (month == 2):\n",
    "        return \"January Dry Season (Kiangazi)\"\n",
    "    elif (month == 3 and day >= 1) or (month < 6):\n",
    "        return \"Long Rains (Masika)\"\n",
    "    else:\n",
    "        return \"Short Rains (Vuli)\"  # Default fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecfac5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_external_temperature() -> pd.DataFrame:\n",
    "    \"\"\"Load external temperature data from Open-Meteo CSV.\"\"\"\n",
    "    try:\n",
    "        if not EXTERNAL_TEMP_FILE.exists():\n",
    "            # VERBOSE: print(f\"Warning: External temperature file not found at {EXTERNAL_TEMP_FILE}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Read CSV, skipping first 3 metadata rows\n",
    "        df = pd.read_csv(EXTERNAL_TEMP_FILE, skiprows=3)\n",
    "        \n",
    "        # Rename columns to match our schema\n",
    "        df = df.rename(columns={\n",
    "            'time': 'datetime',\n",
    "            'temperature_2m (\u00b0C)': 'temperature',\n",
    "            'relative_humidity_2m (%)': 'humidity'\n",
    "        })\n",
    "        \n",
    "        # Add logger_id\n",
    "        df['logger_id'] = 'External (Open-Meteo)'\n",
    "        \n",
    "        # Convert datetime\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "        df['temperature'] = pd.to_numeric(df['temperature'], errors='coerce')\n",
    "        df['humidity'] = pd.to_numeric(df['humidity'], errors='coerce')\n",
    "        \n",
    "        # Drop any invalid rows\n",
    "        df = df.dropna(subset=['datetime', 'temperature', 'humidity'])\n",
    "        \n",
    "        # VERBOSE: print(f\"Loaded {len(df)} external temperature records from Open-Meteo\")\n",
    "        # VERBOSE: print(f\"  Date range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "        \n",
    "        return df[['datetime', 'temperature', 'humidity', 'logger_id']]\n",
    "    \n",
    "    except Exception as e:\n",
    "        # VERBOSE: print(f\"Error loading external temperature: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def load_omnisense_csv(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load and parse Omnisense CSV file with multiple datasets.\"\"\"\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        all_dfs = []\n",
    "        i = 0\n",
    "\n",
    "        while i < len(lines):\n",
    "            # Look for dataset header\n",
    "            if 'sensor_desc,site_name' in lines[i]:\n",
    "                # Get sensor description (next line) - everything except the site name at the end\n",
    "                desc_line = lines[i + 1].strip()\n",
    "                # Remove the site name (e.g., \"ARC CEV Tanzania\") - it's after the last comma\n",
    "                parts = desc_line.split(',')\n",
    "                sensor_desc = ','.join(parts[:-1]) if len(parts) > 1 else parts[0]\n",
    "                sensor_desc = sensor_desc.strip()\n",
    "\n",
    "                # Get column headers (line after description)\n",
    "                col_headers = lines[i + 2].strip().split(',')\n",
    "\n",
    "                # Skip weather station data\n",
    "                if 'Weather Station' in sensor_desc:\n",
    "                    # VERBOSE: print(f\"Skipping {sensor_desc} (weather station)\")\n",
    "                    i += 1\n",
    "                    continue\n",
    "\n",
    "                # Check if this dataset has temperature and humidity\n",
    "                if 'temperature' in col_headers and 'humidity' in col_headers:\n",
    "                    # Find column indices\n",
    "                    temp_idx = col_headers.index('temperature')\n",
    "                    humidity_idx = col_headers.index('humidity')\n",
    "\n",
    "                    # Find datetime column (could be 'read_date' or similar)\n",
    "                    date_col = None\n",
    "                    for col in ['read_date', 'datetime', 'date', 'time']:\n",
    "                        if col in col_headers:\n",
    "                            date_col = col\n",
    "                            date_idx = col_headers.index(col)\n",
    "                            break\n",
    "\n",
    "                    if date_col is None:\n",
    "                        # VERBOSE: print(f\"Warning: No date column found for {sensor_desc}, skipping\")\n",
    "                        i += 1\n",
    "                        continue\n",
    "\n",
    "                    # Find where this dataset ends (next sensor_desc or end of file)\n",
    "                    data_start = i + 3\n",
    "                    data_end = data_start\n",
    "                    for j in range(data_start, len(lines)):\n",
    "                        if 'sensor_desc,site_name' in lines[j]:\n",
    "                            data_end = j\n",
    "                            break\n",
    "                        data_end = j + 1\n",
    "\n",
    "                    # Parse data rows\n",
    "                    data_rows = []\n",
    "                    for row_line in lines[data_start:data_end]:\n",
    "                        row = row_line.strip().split(',')\n",
    "                        if len(row) > max(temp_idx, humidity_idx, date_idx):\n",
    "                            try:\n",
    "                                data_rows.append({\n",
    "                                    'datetime': row[date_idx],\n",
    "                                    'temperature': row[temp_idx],\n",
    "                                    'humidity': row[humidity_idx]\n",
    "                                })\n",
    "                            except (IndexError, ValueError):\n",
    "                                continue\n",
    "\n",
    "                    if data_rows:\n",
    "                        # Create DataFrame for this sensor\n",
    "                        df = pd.DataFrame(data_rows)\n",
    "                        df['logger_id'] = sensor_desc\n",
    "                        df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "                        df['temperature'] = pd.to_numeric(df['temperature'], errors='coerce')\n",
    "                        df['humidity'] = pd.to_numeric(df['humidity'], errors='coerce')\n",
    "                        df = df.dropna()\n",
    "\n",
    "                        if not df.empty:\n",
    "                            all_dfs.append(df)\n",
    "                            # VERBOSE: print(f\"Loaded {len(df)} records from: {sensor_desc}\")\n",
    "\n",
    "                    i = data_end\n",
    "                else:\n",
    "                    # Skip datasets without temperature and humidity\n",
    "                    # VERBOSE: print(f\"Skipping {sensor_desc} (no temperature/humidity data)\")\n",
    "                    i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        if not all_dfs:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Combine all sensor data\n",
    "        return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        # VERBOSE: print(f\"Error loading {path.name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def load_all_data() -> pd.DataFrame:\n",
    "    \"\"\"Load and combine all CSV files from the data folder, plus external temperature.\"\"\"\n",
    "    # Load omnisense sensor data\n",
    "    csv_files = sorted(p for p in DATA_FOLDER.glob(\"*.csv\")\n",
    "                      if not p.name.startswith(\"~$\") and p.name != EXTERNAL_TEMP_FILE.name)\n",
    "\n",
    "    # VERBOSE: print(f\"Found {len(csv_files)} Omnisense CSV file(s) in {DATA_FOLDER}\")\n",
    "\n",
    "    dfs = []\n",
    "    for csv_file in csv_files:\n",
    "        # VERBOSE: print(f\"\\nProcessing {csv_file.name}...\")\n",
    "        df = load_omnisense_csv(csv_file)\n",
    "        if not df.empty:\n",
    "            dfs.append(df)\n",
    "\n",
    "    # Load external temperature data\n",
    "    # VERBOSE: print(f\"\\nLoading external temperature data...\")\n",
    "    external_df = load_external_temperature()\n",
    "    if not external_df.empty:\n",
    "        dfs.append(external_df)\n",
    "\n",
    "    if not dfs:\n",
    "        raise ValueError(f\"No valid data found in {DATA_FOLDER}\")\n",
    "\n",
    "    # VERBOSE: print(f\"\\nTotal datasets loaded: {len(dfs)}\")\n",
    "\n",
    "    # Combine all data\n",
    "    df_all = pd.concat(dfs, ignore_index=True).sort_values(\"datetime\")\n",
    "\n",
    "    # VERBOSE: print(f\"Total records: {len(df_all)}\")\n",
    "    # VERBOSE: print(f\"Unique loggers: {df_all['logger_id'].nunique()}\")\n",
    "    # VERBOSE: print(f\"Logger IDs: {sorted(df_all['logger_id'].unique())}\")\n",
    "\n",
    "    # Ensure timezone-aware datetimes\n",
    "    df_all[\"datetime\"] = (\n",
    "        pd.to_datetime(df_all[\"datetime\"], errors=\"coerce\")\n",
    "        .dt.tz_localize(TIMEZONE, nonexistent=\"shift_forward\", ambiguous=\"NaT\")\n",
    "    )\n",
    "\n",
    "    df_all = df_all.dropna(subset=[\"datetime\"]).set_index(\"datetime\").sort_index()\n",
    "\n",
    "    # Precompute ISO calendar\n",
    "    iso = df_all.index.isocalendar()\n",
    "    df_all[\"iso_year\"] = iso.year\n",
    "    df_all[\"iso_week\"] = iso.week\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f106abe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 Omnisense CSV file(s) in data/omnisense\n",
      "\n",
      "Processing 070226.csv...\n",
      "Loaded 2501 records from: House 5, Kitchen\n",
      "Loaded 2416 records from: House 5, Bed 4\n",
      "Loaded 2498 records from: House 5, Bed 4, above ceiling\n",
      "Loaded 2500 records from: House 5, Bed 2\n",
      "Loaded 2499 records from: House 5, Living Room\n",
      "Loaded 2498 records from: House 5, Mother's Bedroom\n",
      "Loaded 2499 records from: House 5, Washrooms area\n",
      "Loaded 2500 records from: House 3, Bed 2\n",
      "Loaded 2498 records from: House 5, Bed 3\n",
      "Skipping Sun, Wind, Rain weather station gateway (in external box) (no temperature/humidity data)\n",
      "Skipping Weather Station, T & RH (weather station)\n",
      "Loaded 4583 records from: House 5, Metal Roof, above Bed 4\n",
      "Skipping Performance stats (no temperature/humidity data)\n",
      "\n",
      "Loading external temperature data...\n",
      "Loaded 504 external temperature records from Open-Meteo\n",
      "  Date range: 2026-01-17 00:00:00 to 2026-02-06 23:00:00\n",
      "\n",
      "Total datasets loaded: 2\n",
      "Total records: 27496\n",
      "Unique loggers: 11\n",
      "Logger IDs: ['External (Open-Meteo)', 'House 3, Bed 2', 'House 5, Bed 2', 'House 5, Bed 3', 'House 5, Bed 4', 'House 5, Bed 4, above ceiling', 'House 5, Kitchen', 'House 5, Living Room', 'House 5, Metal Roof, above Bed 4', \"House 5, Mother's Bedroom\", 'House 5, Washrooms area']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df_all = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777a0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colour_map(loggers: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"Create a colour mapping for loggers with normal, distinct colors.\"\"\"\n",
    "    # Standard color palette with good contrast\n",
    "    colors = [\n",
    "        \"#1f77b4\",  # Blue\n",
    "        \"#ff7f0e\",  # Orange  \n",
    "        \"#2ca02c\",  # Green\n",
    "        \"#d62728\",  # Red\n",
    "        \"#9467bd\",  # Purple\n",
    "        \"#8c564b\",  # Brown\n",
    "        \"#e377c2\",  # Pink\n",
    "        \"#7f7f7f\",  # Gray\n",
    "        \"#bcbd22\",  # Olive\n",
    "        \"#17becf\",  # Cyan\n",
    "        \"#aec7e8\",  # Light Blue\n",
    "        \"#ffbb78\",  # Light Orange\n",
    "        \"#98df8a\",  # Light Green\n",
    "        \"#ff9896\",  # Light Red\n",
    "        \"#c5b0d5\",  # Light Purple\n",
    "        \"#c49c94\",  # Light Brown\n",
    "        \"#f7b6d3\",  # Light Pink\n",
    "        \"#c7c7c7\",  # Light Gray\n",
    "        \"#dbdb8d\",  # Light Olive\n",
    "        \"#9edae5\",  # Light Cyan\n",
    "        \"#393b79\",  # Dark Blue\n",
    "        \"#637939\",  # Dark Green\n",
    "        \"#8c6d31\",  # Dark Orange\n",
    "        \"#843c39\"   # Dark Red\n",
    "    ]\n",
    "    return {logger: colors[i % len(colors)] for i, logger in enumerate(loggers)}\n",
    "\n",
    "\n",
    "def create_checkboxes(items: List[str], default: bool = True) -> Dict[str, widgets.Checkbox]:\n",
    "    \"\"\"Create a dictionary of checkboxes for items.\"\"\"\n",
    "    return {\n",
    "        item: widgets.Checkbox(\n",
    "            value=default,\n",
    "            description=str(item),\n",
    "            indent=False,\n",
    "            layout=widgets.Layout(height=\"18px\")\n",
    "        )\n",
    "        for item in items\n",
    "    }\n",
    "\n",
    "\n",
    "def create_time_selectors(df: pd.DataFrame) -> Tuple:\n",
    "    \"\"\"Create all time selection widgets.\"\"\"\n",
    "    date_min, date_max = df.index.min(), df.index.max()\n",
    "    \n",
    "    # Time mode dropdown\n",
    "    time_mode = widgets.Dropdown(\n",
    "        options=[\"All time\", \"Between dates\", \"Year\", \"Month\", \"Week\", \"Day\"],\n",
    "        value=\"All time\",\n",
    "        description=\"Range:\",\n",
    "        layout=widgets.Layout(width=\"200px\")\n",
    "    )\n",
    "    \n",
    "    # Between dates selector\n",
    "    between_box = widgets.HBox([\n",
    "        widgets.DatetimePicker(description=\"Start\", value=date_min, step=60),\n",
    "        widgets.DatetimePicker(description=\"End\", value=date_max, step=60)\n",
    "    ])\n",
    "    \n",
    "    # Year selector\n",
    "    available_years = sorted(df.index.year.unique())\n",
    "    year_select = widgets.Dropdown(\n",
    "        options=available_years, \n",
    "        description=\"Year:\", \n",
    "        layout=widgets.Layout(display=\"none\")\n",
    "    )\n",
    "    \n",
    "    # Month selector\n",
    "    available_months = sorted({(y, m) for y, m in zip(df.index.year, df.index.month)})\n",
    "    month_select = widgets.Dropdown(\n",
    "        options=[(f\"{dt.date(y, m, 1):%B %Y}\", (y, m)) for y, m in available_months],\n",
    "        description=\"Month:\",\n",
    "        layout=widgets.Layout(display=\"none\")\n",
    "    )\n",
    "    \n",
    "    # Week selector\n",
    "    available_weeks = sorted({(y, int(w)) for y, w in zip(df[\"iso_year\"], df[\"iso_week\"])})\n",
    "    week_select = widgets.Dropdown(\n",
    "        options=[(f\"Week {w}, {y}\", (y, w)) for y, w in available_weeks],\n",
    "        description=\"Week:\",\n",
    "        layout=widgets.Layout(display=\"none\")\n",
    "    )\n",
    "    \n",
    "    # Day selector\n",
    "    available_days = sorted(df.index.normalize().unique())\n",
    "    day_select = widgets.Dropdown(\n",
    "        options=[(d.strftime(\"%d %b %Y\"), d) for d in available_days],\n",
    "        description=\"Day:\",\n",
    "        layout=widgets.Layout(display=\"none\")\n",
    "    )\n",
    "    \n",
    "    return time_mode, between_box, year_select, month_select, week_select, day_select\n",
    "\n",
    "\n",
    "def create_gap_broken_traces(df: pd.DataFrame, selected_metrics: list, logger_display_names: dict, colour_map: dict, max_gap_hours: float = 12.0):\n",
    "    \"\"\"Create separate traces for each logger, breaking on large time gaps.\"\"\"\n",
    "    traces = []\n",
    "    \n",
    "    if df.empty:\n",
    "        return traces\n",
    "    \n",
    "    gap_threshold = pd.Timedelta(hours=max_gap_hours)\n",
    "    \n",
    "    # Group by logger_id to handle each logger separately\n",
    "    for logger_id in df['logger_id'].unique():\n",
    "        logger_data = df[df['logger_id'] == logger_id].copy().sort_index()\n",
    "        \n",
    "        if logger_data.empty:\n",
    "            continue\n",
    "            \n",
    "        logger_display_name = logger_display_names.get(logger_id, logger_id)\n",
    "        logger_color = colour_map.get(logger_id, \"#1f77b4\")\n",
    "        \n",
    "        # Find gap locations\n",
    "        if len(logger_data) < 2:\n",
    "            # Single point or empty - create one trace\n",
    "            gap_indices = []\n",
    "        else:\n",
    "            time_diffs = logger_data.index.to_series().diff()\n",
    "            large_gaps = time_diffs > gap_threshold\n",
    "            gap_indices = logger_data.index[large_gaps].tolist()\n",
    "        \n",
    "        # Split data at gap locations\n",
    "        start_idx = 0\n",
    "        logger_indices = logger_data.index.tolist()\n",
    "        \n",
    "        sub_trace_count = 0\n",
    "        first_trace_per_logger = False  # Track if we've shown legend for this logger yet\n",
    "        \n",
    "        for gap_idx in gap_indices + [None]:  # Add None to handle the last segment\n",
    "            if gap_idx is not None:\n",
    "                end_idx = logger_indices.index(gap_idx)\n",
    "            else:\n",
    "                end_idx = len(logger_indices)\n",
    "            \n",
    "            if start_idx < end_idx:\n",
    "                # Create sub-trace for this segment\n",
    "                segment_data = logger_data.iloc[start_idx:end_idx]\n",
    "                \n",
    "                if not segment_data.empty:\n",
    "                    for metric in selected_metrics:\n",
    "                        if metric in segment_data.columns:\n",
    "                            # Ensure no None values in x or name\n",
    "                            x_values = segment_data.index.tolist()\n",
    "                            y_values = segment_data[metric].tolist()\n",
    "                            \n",
    "                            # Filter out any None/NaN values\n",
    "                            valid_pairs = [(x, y) for x, y in zip(x_values, y_values) \n",
    "                                         if x is not None and pd.notna(y)]\n",
    "                            \n",
    "                            if valid_pairs:\n",
    "                                x_clean, y_clean = zip(*valid_pairs)\n",
    "                                \n",
    "                                # Only show in legend for the very first trace of this logger\n",
    "                                show_legend = not first_trace_per_logger\n",
    "                                if show_legend:\n",
    "                                    first_trace_per_logger = True\n",
    "                                \n",
    "                                # Determine units for hover template\n",
    "                                if metric == \"temperature\":\n",
    "                                    unit = \"\u00b0C\"\n",
    "                                else:  # humidity\n",
    "                                    unit = \"%RH\"\n",
    "                                \n",
    "                                trace = go.Scatter(\n",
    "                                    x=list(x_clean),\n",
    "                                    y=list(y_clean),\n",
    "                                    mode='lines',\n",
    "                                    name=logger_display_name,\n",
    "                                    line=dict(color=logger_color),\n",
    "                                    showlegend=show_legend,\n",
    "                                    connectgaps=False,\n",
    "                                    legendgroup=logger_display_name,  # Group all sub-traces together\n",
    "                                    hovertemplate=f\"{logger_display_name}<br>%{{x|%d/%m/%Y %H:%M}}<br>{metric.title()}: %{{y:.2f}}{unit}<extra></extra>\"\n",
    "                                )\n",
    "                                traces.append(trace)\n",
    "                    \n",
    "                    sub_trace_count += 1\n",
    "            \n",
    "            start_idx = end_idx\n",
    "    \n",
    "    return traces\n",
    "\n",
    "\n",
    "def get_time_mask(df: pd.DataFrame, mode: str, selectors: Dict) -> pd.Series:\n",
    "    \"\"\"Generate boolean mask based on time selection mode.\"\"\"\n",
    "    selected_loggers = selectors[\"selected_loggers\"]\n",
    "    logger_mask = df[\"logger_id\"].isin(selected_loggers)\n",
    "    \n",
    "    if mode == \"All time\":\n",
    "        return logger_mask\n",
    "    \n",
    "    elif mode == \"Between dates\":\n",
    "        start = pd.Timestamp(selectors[\"between_box\"].children[0].value).tz_convert(TIMEZONE)\n",
    "        end = pd.Timestamp(selectors[\"between_box\"].children[1].value).tz_convert(TIMEZONE)\n",
    "        return (df.index >= start) & (df.index <= end) & logger_mask\n",
    "    \n",
    "    elif mode == \"Year\":\n",
    "        year = int(selectors[\"year_select\"].value)\n",
    "        return (df.index.year == year) & logger_mask\n",
    "    \n",
    "    elif mode == \"Month\":\n",
    "        year, month = selectors[\"month_select\"].value\n",
    "        return (df.index.year == year) & (df.index.month == month) & logger_mask\n",
    "    \n",
    "    elif mode == \"Week\":\n",
    "        year, week = selectors[\"week_select\"].value\n",
    "        return (df[\"iso_year\"] == year) & (df[\"iso_week\"] == week) & logger_mask\n",
    "    \n",
    "    elif mode == \"Day\":\n",
    "        day = selectors[\"day_select\"].value.tz_convert(TIMEZONE)\n",
    "        return (df.index.normalize() == day.normalize()) & logger_mask\n",
    "    \n",
    "    return logger_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_adaptive_comfort_data(df: pd.DataFrame, time_mask: pd.Series, external_logger: str, room_loggers: list) -> pd.DataFrame:\n",
    "    \"\"\"Prepare data for adaptive comfort chart using 7-day rolling mean of DAILY external temperature.\"\"\"\n",
    "    # Filter for time range first\n",
    "    df_filtered = df[time_mask].copy()\n",
    "    \n",
    "    # Get external temperature data\n",
    "    if external_logger and external_logger in df_filtered[\"logger_id\"].values:\n",
    "        external_data = df_filtered[df_filtered[\"logger_id\"] == external_logger][[\"temperature\"]].copy()\n",
    "    else:\n",
    "        # If no external logger specified, return empty\n",
    "        print(\"Warning: No external temperature data available for adaptive comfort calculation\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    external_data.columns = [\"external_temp\"]\n",
    "    \n",
    "    # Step 1: Calculate DAILY mean external temperature\n",
    "    daily_means = external_data.resample(\"d\").mean()\n",
    "    \n",
    "    # Step 2: Calculate 7-day rolling mean of the daily means\n",
    "    # This uses the previous 7 days including today\n",
    "    daily_means[\"external_temp_7day_mean\"] = daily_means[\"external_temp\"].rolling(\n",
    "        window=7, \n",
    "        min_periods=1\n",
    "    ).mean()\n",
    "    \n",
    "    # Step 3: Upsample back to original frequency (forward-fill the daily values)\n",
    "    # This assigns each hour/minute the same daily rolling mean value\n",
    "    external_with_running_mean = daily_means[[\"external_temp_7day_mean\"]].resample(\"h\").ffill()\n",
    "    \n",
    "    # Step 4: Get room data\n",
    "    room_data = df_filtered[df_filtered[\"logger_id\"].isin(room_loggers)].copy()\n",
    "    \n",
    "    # Step 5: Merge room data with 7-day rolling mean external temperature\n",
    "    # Use merge_asof to match each room measurement with the closest external temperature\n",
    "    room_data = room_data.reset_index().sort_values(\"datetime\")\n",
    "    external_reset = external_with_running_mean.reset_index().sort_values(\"datetime\")\n",
    "    \n",
    "    room_data = pd.merge_asof(\n",
    "        room_data,\n",
    "        external_reset.rename(columns={\"datetime\": \"datetime\"}),\n",
    "        on=\"datetime\",\n",
    "        direction=\"nearest\"\n",
    "    )\n",
    "    \n",
    "    # Set datetime back as index\n",
    "    room_data = room_data.set_index(\"datetime\")\n",
    "    \n",
    "    # Rename column to match expected name in other functions\n",
    "    room_data = room_data.rename(columns={\"external_temp_7day_mean\": \"external_temp\"})\n",
    "    \n",
    "    # Drop rows with missing external temperature\n",
    "    room_data = room_data.dropna(subset=[\"external_temp\"])\n",
    "    \n",
    "    return room_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e818853",
   "metadata": {},
   "outputs": [],
   "source": "class LoggerDataViewer:\n    \"\"\"Interactive logger data viewer with filtering capabilities.\"\"\"\n    \n    def __init__(self):\n        self.df = load_all_data()\n        self._setup_config()\n        self._create_all_widgets()\n        self._create_layout()\n        self._setup_observers()\n    \n    def _setup_config(self):\n        \"\"\"Setup configuration based on loaded data.\"\"\"\n        # Determine loggers from actual data\n        unique_loggers_in_data = sorted(self.df[\"logger_id\"].unique())\n        self.unique_loggers = unique_loggers_in_data\n        \n        # Identify external temperature logger\n        if \"External (Open-Meteo)\" in unique_loggers_in_data:\n            self.external_logger = \"External (Open-Meteo)\"\n            # Room loggers are all except external\n            self.room_loggers = [l for l in unique_loggers_in_data if l != \"External (Open-Meteo)\"]\n        else:\n            # Fallback if external not found\n            self.external_logger = None\n            self.room_loggers = unique_loggers_in_data\n            # VERBOSE: print(\"Warning: External temperature logger not found!\")\n        \n        self.colour_map = create_colour_map(self.unique_loggers)\n        \n        # Map logger IDs to display names\n        self.logger_display_names = {\n            logger_id: LOGGER_NAMES.get(logger_id, logger_id) \n            for logger_id in self.unique_loggers\n        }\n        \n        # VERBOSE: print(f\"Found loggers: {self.unique_loggers}\")\n        # VERBOSE: print(f\"External logger: {self.external_logger}\")\n        # VERBOSE: print(f\"Room loggers: {self.room_loggers}\")"
  },
  {
   "cell_type": "code",
   "id": "9mpr8askxzj",
   "source": "# Store reference to display function for use in class methods\n_ipython_display = display",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "szpb65ivkr",
   "source": "# Widget creation methods\ndef _create_all_widgets(self):\n    \"\"\"Create all widgets based on current configuration.\"\"\"\n    # Chart type selector\n    self.chart_type = widgets.Dropdown(\n        options=[\"Line Graph\", \"Adaptive Comfort\"],\n        value=\"Line Graph\",\n        description=\"Chart Type:\",\n        layout=widgets.Layout(width=\"200px\")\n    )\n    \n    # Comfort model selector for adaptive comfort\n    self.boundary_model = widgets.Dropdown(\n        options=[\n            (\"Default model\", \"default\"),\n            (\"RH>60% (Vellei et al.)\", \"rh_gt_60\"),\n            (\"40%<RH\u226460% (Vellei et al.)\", \"rh_40_60\"),\n            (\"RH\u226440% (Vellei et al.)\", \"rh_le_40\"),\n            (\"None\", \"none\"),\n        ],\n        value=\"default\",\n        description=\"Comfort:\",\n        layout=widgets.Layout(width=\"320px\")\n    )\n    \n    # Create widgets\n    self.logger_checkboxes = create_checkboxes([\n        self.logger_display_names[logger_id] for logger_id in self.unique_loggers\n    ])\n    self.metric_checkboxes = create_checkboxes([\"Temperature\", \"Humidity\"])\n    \n    # Create room logger checkboxes for adaptive comfort chart\n    self.room_logger_checkboxes = create_checkboxes([\n        self.logger_display_names[logger_id] for logger_id in self.room_loggers if logger_id in self.unique_loggers\n    ])\n    \n    # Create comfort percentage display\n    self.comfort_stats_out = widgets.Output()\n    \n    # Add 32\u00b0C threshold checkbox\n    self.threshold_checkbox = widgets.Checkbox(\n        value=True,\n        description=\"32\u00b0C Threshold\",\n        indent=False,\n        layout=widgets.Layout(height=\"18px\")\n    )\n    \n    # Add season lines checkbox\n    self.season_lines_checkbox = widgets.Checkbox(\n        value=True,\n        description=\"Season Lines\",\n        indent=False,\n        layout=widgets.Layout(height=\"18px\")\n    )\n    \n    # Add download buttons\n    self.download_button = widgets.Button(\n        description=\"Download Chart\",\n        button_style=\"success\",\n        layout=widgets.Layout(width=\"150px\")\n    )\n    \n    self.download_with_stats_button = widgets.Button(\n        description=\"Download with Stats\",\n        button_style=\"info\",\n        layout=widgets.Layout(width=\"150px\")\n    )\n    \n    (self.time_mode, self.between_box, self.year_select, \n     self.month_select, self.week_select, self.day_select) = create_time_selectors(self.df)\n    \n    self.plot_out = widgets.Output()\n    self.loading_out = widgets.Output(layout=widgets.Layout(height=\"30px\"))\n    # Debug output removed for Voil\u00e0 compatibility\n\ndef _create_layout(self):\n    \"\"\"Create the widget layout.\"\"\"\n    logger_box = widgets.VBox(\n        [widgets.HTML(\"<b>Loggers</b>\")] + list(self.logger_checkboxes.values()) + [self.threshold_checkbox, self.season_lines_checkbox],\n        layout=widgets.Layout(width=\"300px\")\n    )\n    \n    metric_box = widgets.VBox(\n        [widgets.HTML(\"<b>Metrics</b>\")] + list(self.metric_checkboxes.values()),\n        layout=widgets.Layout(width=\"150px\")\n    )\n    \n    room_logger_box = widgets.VBox(\n        [widgets.HTML(\"<b>Room Loggers</b>\")] + list(self.room_logger_checkboxes.values()),\n        layout=widgets.Layout(width=\"300px\")\n    )\n    \n    # Comfort stats box for adaptive comfort\n    comfort_stats_box = widgets.VBox([\n        widgets.HTML(\"<b>Comfort Statistics</b>\"),\n        self.comfort_stats_out\n    ], layout=widgets.Layout(width=\"400px\", margin=\"0px 0px 20px 0px\"))\n    \n    download_box = widgets.VBox([\n        widgets.HTML(\"<b>Export</b>\"),\n        self.download_button,\n        self.download_with_stats_button,\n        self.loading_out\n    ], layout=widgets.Layout(width=\"150px\"))\n    \n    self.time_controls = widgets.VBox([\n        self.chart_type,\n        self.boundary_model,\n        self.time_mode, \n        self.between_box, \n        self.year_select, \n        self.month_select, \n        self.week_select, \n        self.day_select\n    ])\n    \n    self.logger_box = logger_box\n    self.metric_box = metric_box\n    self.room_logger_box = room_logger_box\n    self.comfort_stats_box = comfort_stats_box\n    self.controls = widgets.HBox([logger_box, metric_box, room_logger_box, comfort_stats_box, download_box])\n    \n    # Initial visibility\n    self._update_controls_visibility()\n\nLoggerDataViewer._create_all_widgets = _create_all_widgets\nLoggerDataViewer._create_layout = _create_layout",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "yjzv7ld6ofr",
   "source": "# Observer and event handler methods\ndef _setup_observers(self):\n    \"\"\"Set up all widget observers.\"\"\"\n    # Time mode visibility\n    self.time_mode.observe(self._update_visibility, \"value\")\n    \n    # Chart type changes\n    self.chart_type.observe(self._on_chart_type_change, \"value\")\n    \n    # Comfort model changes\n    self.boundary_model.observe(self._on_widget_change, \"value\")\n    \n    # Plot updates\n    for cb in list(self.logger_checkboxes.values()) + list(self.metric_checkboxes.values()) + list(self.room_logger_checkboxes.values()):\n        cb.observe(self._on_checkbox_change, \"value\")\n    \n    self.threshold_checkbox.observe(self._on_checkbox_change, \"value\")\n    self.season_lines_checkbox.observe(self._on_checkbox_change, \"value\")\n    self.download_button.on_click(self._download_chart)\n    self.download_with_stats_button.on_click(self._download_chart_with_stats)\n    \n    for widget in [self.between_box.children[0], self.between_box.children[1],\n                  self.year_select, self.month_select, self.week_select, self.day_select]:\n        widget.observe(self._on_time_widget_change, \"value\")\n\ndef _on_chart_type_change(self, change):\n    \"\"\"Handler for chart type changes.\"\"\"\n    self._debug_log(f\"*** CHART TYPE CHANGE: {change['new']} ***\")\n    self._update_controls_visibility()\n    self.update_plot()\n\ndef _on_checkbox_change(self, change):\n    \"\"\"Handler for checkbox changes.\"\"\"\n    self._debug_log(f\"*** CHECKBOX CHANGE: {change['owner'].description} = {change['new']} ***\")\n    self.update_plot()\n\ndef _on_widget_change(self, change):\n    \"\"\"Handler for widget changes.\"\"\"\n    self._debug_log(f\"*** WIDGET CHANGE: {change['owner'].description} = {change['new']} ***\")\n    self.update_plot()\n\ndef _on_time_widget_change(self, change):\n    \"\"\"Handler for time widget changes with loading indicator.\"\"\"\n    self._debug_log(f\"*** TIME WIDGET CHANGE: {change['owner'].description} = {change['new']} ***\")\n    self.update_plot()\n\ndef _update_controls_visibility(self):\n    \"\"\"Update visibility of controls based on chart type.\"\"\"\n    is_line_graph = self.chart_type.value == \"Line Graph\"\n    \n    # Show/hide logger and metric boxes\n    self.logger_box.layout.display = \"flex\" if is_line_graph else \"none\"\n    self.metric_box.layout.display = \"flex\" if is_line_graph else \"none\"\n    \n    # Show/hide room logger box for adaptive comfort\n    self.room_logger_box.layout.display = \"none\" if is_line_graph else \"flex\"\n    \n    # Show/hide comfort stats box for adaptive comfort\n    self.comfort_stats_box.layout.display = \"none\" if is_line_graph else \"flex\"\n    \n    # Show/hide download with stats button for adaptive comfort\n    self.download_with_stats_button.layout.display = \"none\" if is_line_graph else \"flex\"\n    \n    # Show comfort model selector only for adaptive comfort\n    self.boundary_model.layout.display = \"none\" if is_line_graph else \"flex\"\n\ndef _update_visibility(self, change):\n    \"\"\"Update visibility of time selectors based on mode.\"\"\"\n    self._debug_log(f\"*** TIME MODE VISIBILITY CHANGE: {change['new']} ***\")\n    \n    # Hide all\n    for widget in [self.between_box, self.year_select, self.month_select, \n                  self.week_select, self.day_select]:\n        widget.layout.display = \"none\"\n    \n    # Show relevant selector\n    mode = change[\"new\"]\n    visibility_map = {\n        \"Between dates\": self.between_box,\n        \"Year\": self.year_select,\n        \"Month\": self.month_select,\n        \"Week\": self.week_select,\n        \"Day\": self.day_select\n    }\n    \n    if mode in visibility_map:\n        visibility_map[mode].layout.display = \"flex\"\n    \n    # Update plot when time mode changes\n    self.update_plot()\n\ndef _show_loading(self):\n    \"\"\"Show loading indicator.\"\"\"\n    with self.loading_out:\n        # VERBOSE: print(\"Loading...\")\n        pass\n\ndef _hide_loading(self):\n    \"\"\"Hide loading indicator.\"\"\"\n    self.loading_out.clear_output()\n\ndef _debug_log(self, message):\n    \"\"\"Debug logging disabled for Voil\u00e0.\"\"\"\n    pass\n\nLoggerDataViewer._setup_observers = _setup_observers\nLoggerDataViewer._on_chart_type_change = _on_chart_type_change\nLoggerDataViewer._on_checkbox_change = _on_checkbox_change\nLoggerDataViewer._on_widget_change = _on_widget_change\nLoggerDataViewer._on_time_widget_change = _on_time_widget_change\nLoggerDataViewer._update_controls_visibility = _update_controls_visibility\nLoggerDataViewer._update_visibility = _update_visibility\nLoggerDataViewer._show_loading = _show_loading\nLoggerDataViewer._hide_loading = _hide_loading\nLoggerDataViewer._debug_log = _debug_log",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6w5k2ay6lk",
   "source": "# Main plot update method\ndef update_plot(self):\n    \"\"\"Update the plot based on current selections.\"\"\"\n    self._debug_log(\"=== Starting update_plot() ===\")\n    self._debug_log(f\"Chart type: {self.chart_type.value}\")\n    self._debug_log(f\"Time mode: {self.time_mode.value}\")\n    \n    self._show_loading()\n    self.plot_out.clear_output(wait=True)\n    \n    try:\n        with self.plot_out:\n            self._debug_log(\"Generating new plot...\")\n            if self.chart_type.value == \"Line Graph\":\n                fig = self._plot_line_graph()\n            else:\n                fig = self._plot_adaptive_comfort()\n            \n            if fig is not None:\n                self._debug_log(\"Plot generated successfully, updating current_fig\")\n                self.current_fig = fig\n                self._debug_log(\"Displaying new plot\")\n                fig.show(config={\n                    'displayModeBar': True,\n                    'modeBarButtonsToRemove': [\n                        'zoom2d', 'pan2d', 'select2d', 'lasso2d', 'zoomIn2d', 'zoomOut2d',\n                        'resetScale2d', 'toImage', 'sendDataToCloud', 'hoverClosestCartesian',\n                        'hoverCompareCartesian', 'toggleHover', 'toggleSpikelines'\n                    ]\n                })\n                self._debug_log(\"Plot displayed successfully\")\n            else:\n                self._debug_log(\"Plot generation returned None - no plot to display\")\n                # Create and display empty placeholder figure\n                empty_fig = go.Figure()\n                empty_fig.add_annotation(\n                    text=\"No data available for current selection\",\n                    xref=\"paper\", yref=\"paper\",\n                    x=0.5, y=0.5, xanchor='center', yanchor='middle',\n                    font=dict(size=16, color=\"gray\")\n                )\n                empty_fig.update_layout(\n                    height=400, width=800,\n                    template=\"plotly_white\",\n                    showlegend=False,\n                    xaxis=dict(visible=False),\n                    yaxis=dict(visible=False)\n                )\n                self.current_fig = empty_fig\n                empty_fig.show(config={\n                    'displayModeBar': True,\n                    'modeBarButtonsToRemove': [\n                        'zoom2d', 'pan2d', 'select2d', 'lasso2d', 'zoomIn2d', 'zoomOut2d',\n                        'resetScale2d', 'toImage', 'sendDataToCloud', 'hoverClosestCartesian',\n                        'hoverCompareCartesian', 'toggleHover', 'toggleSpikelines'\n                    ]\n                })\n                self._debug_log(\"Displayed empty placeholder figure\")\n    except Exception as e:\n        import traceback\n        error_msg = f\"Error in update_plot: {e}\\n{traceback.format_exc()}\"\n        self._debug_log(error_msg)\n        # VERBOSE: print(error_msg)\n        # Don't update current_fig on error to preserve last good plot\n    finally:\n        self._hide_loading()\n        self._debug_log(\"=== Finished update_plot() ===\")\n\nLoggerDataViewer.update_plot = update_plot",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "zi7szun5dc",
   "source": "# Line graph plotting method (Part 1: data preparation and figure creation)\ndef _plot_line_graph(self):\n    \"\"\"Generate line graph plot.\"\"\"\n    self._debug_log(\"--- Starting _plot_line_graph() ---\")\n    \n    # Map display names back to logger IDs\n    selected_display_names = [l for l, cb in self.logger_checkboxes.items() if cb.value]\n    name_to_id = {v: k for k, v in self.logger_display_names.items()}\n    selected_loggers = [name_to_id[name] for name in selected_display_names]\n    \n    selected_metrics = [m.lower() for m, cb in self.metric_checkboxes.items() if cb.value]\n    \n    self._debug_log(f\"Selected loggers: {selected_loggers}\")\n    self._debug_log(f\"Selected metrics: {selected_metrics}\")\n    \n    if not selected_loggers or not selected_metrics:\n        self._debug_log(\"No loggers or metrics selected - returning None\")\n        # VERBOSE: print(\"Select at least one logger and one metric.\")\n        return None\n    \n    mode = self.time_mode.value\n    \n    selectors = {\n        \"selected_loggers\": selected_loggers,\n        \"between_box\": self.between_box,\n        \"year_select\": self.year_select,\n        \"month_select\": self.month_select,\n        \"week_select\": self.week_select,\n        \"day_select\": self.day_select\n    }\n    \n    mask = get_time_mask(self.df, mode, selectors)\n    subset = self.df[mask].copy()\n    \n    self._debug_log(f\"Original data shape: {self.df.shape}\")\n    self._debug_log(f\"Filtered data shape: {subset.shape}\")\n    \n    if subset.empty:\n        self._debug_log(\"Filtered data is empty - returning None\")\n        # VERBOSE: print(\"No data for selected filters.\")\n        return None\n    \n    self._debug_log(f\"Data shape before gap processing: {subset.shape}\")\n    \n    # Create dynamic title based on selected metrics\n    if len(selected_metrics) == 2:  # Both temperature and humidity\n        title_suffix = \"Temperature & Humidity\"\n    elif \"temperature\" in selected_metrics:  # Only temperature\n        title_suffix = \"Temperature\"\n    else:  # Only humidity\n        title_suffix = \"Humidity\"\n    \n    title = f\"<b>Omnisense Monitoring \u2013 {title_suffix}</b>\"\n    \n    # Create empty figure with title\n    fig = go.Figure()\n    fig.update_layout(title=title)\n    \n    # Line thickness proportional to \"complexity\" (time span proxy)\n    if mode == \"All time\":\n        line_width = 1.0\n    elif mode in (\"Between dates\", \"Year\", \"Month\", \"Week\"):\n        line_width = 1.4\n    elif mode == \"Day\":\n        line_width = 2.2\n    else:\n        line_width = 1.6\n    \n    # Create gap-broken traces for each logger\n    self._debug_log(\"Creating gap-broken traces...\")\n    traces = create_gap_broken_traces(\n        subset, \n        selected_metrics, \n        self.logger_display_names, \n        self.colour_map, \n        max_gap_hours=12.0\n    )\n    \n    # Add each trace to the figure\n    for i, trace in enumerate(traces):\n        self._debug_log(f\"Adding trace {i}: Logger={trace.legendgroup}, Points={len(trace.x)}, Name='{trace.name}', ShowLegend={trace.showlegend}\")\n        trace.line.width = line_width\n        trace.opacity = 0.85\n        fig.add_trace(trace)\n    \n    # Store for use in part 2\n    return self._plot_line_graph_part2(fig, subset, selected_metrics, selected_loggers, mode)\n\nLoggerDataViewer._plot_line_graph = _plot_line_graph",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "iqcbvcoyvon",
   "source": "# Line graph plotting method (Part 2: axes, formatting, and decorations)\ndef _plot_line_graph_part2(self, fig, subset, selected_metrics, selected_loggers, mode):\n    \"\"\"Complete line graph with axes, threshold, and season lines.\"\"\"\n    \n    # Update axis labels with custom formatting based on selected metrics\n    if len(selected_metrics) == 2:  # Both temperature and humidity\n        y_title = \"Temperature/Humidity\"\n        y_suffix = \"\u00b0C/%RH\"\n    elif \"temperature\" in selected_metrics:  # Only temperature\n        y_title = \"Temperature\"\n        y_suffix = \"\u00b0C\"\n    else:  # Only humidity\n        y_title = \"Humidity\"\n        y_suffix = \"%RH\"\n    \n    fig.update_yaxes(\n        title_text=y_title,\n        tickformat=\"\",  # Let plotly choose appropriate decimal places\n        ticksuffix=y_suffix\n    )\n    \n    # Custom x-axis formatting based on time mode\n    if mode == \"Day\":\n        # Show hours and minutes for single day\n        fig.update_xaxes(\n            title_text=\"Time\",\n            tickformat=\"%H:%M\",\n            dtick=3600000  # 1 hour intervals\n        )\n    elif mode == \"Week\":\n        # Show day and time for week view\n        fig.update_xaxes(\n            title_text=\"Date/Time\",\n            tickformat=\"%a %d<br>%H:%M\",\n            dtick=21600000  # 6 hour intervals\n        )\n    elif mode == \"Month\":\n        # Show date and time for month view\n        fig.update_xaxes(\n            title_text=\"Date/Time\",\n            tickformat=\"%d %b<br>%H:%M\",\n            dtick=86400000  # 1 day intervals\n        )\n    elif mode == \"Year\":\n        # Show month and day for year view\n        fig.update_xaxes(\n            title_text=\"Date\",\n            tickformat=\"%b %d\",\n            dtick=\"M1\"  # Monthly intervals\n        )\n    elif mode == \"Between dates\":\n        # Determine appropriate format based on date range\n        date_range = (subset.index.max() - subset.index.min()).days\n        if date_range <= 1:\n            # Less than 1 day - show hours\n            fig.update_xaxes(\n                title_text=\"Time\",\n                tickformat=\"%H:%M\",\n                dtick=3600000  # 1 hour intervals\n            )\n        elif date_range <= 7:\n            # Less than 1 week - show day and time\n            fig.update_xaxes(\n                title_text=\"Date/Time\",\n                tickformat=\"%a %d<br>%H:%M\",\n                dtick=21600000  # 6 hour intervals\n            )\n        elif date_range <= 31:\n            # Less than 1 month - show date and time\n            fig.update_xaxes(\n                title_text=\"Date/Time\",\n                tickformat=\"%d %b<br>%H:%M\",\n                dtick=86400000  # 1 day intervals\n            )\n        elif date_range <= 365:\n            # Less than 1 year - show month and day\n            fig.update_xaxes(\n                title_text=\"Date\",\n                tickformat=\"%b %d\",\n                dtick=\"M1\"  # Monthly intervals\n            )\n        else:\n            # More than 1 year - show year and month\n            fig.update_xaxes(\n                title_text=\"Date\",\n                tickformat=\"%Y<br>%b\",\n                dtick=\"M3\"  # Quarterly intervals\n            )\n    else:\n        # All time - adaptive based on total data range\n        total_range = (self.df.index.max() - self.df.index.min()).days\n        if total_range <= 31:\n            fig.update_xaxes(\n                title_text=\"Date/Time\",\n                tickformat=\"%d %b<br>%H:%M\",\n                dtick=86400000  # 1 day intervals\n            )\n        elif total_range <= 365:\n            fig.update_xaxes(\n                title_text=\"Date\",\n                tickformat=\"%b %d\",\n                dtick=\"M1\"  # Monthly intervals\n            )\n        else:\n            fig.update_xaxes(\n                title_text=\"Date\",\n                tickformat=\"%Y<br>%b\",\n                dtick=\"M3\"  # Quarterly intervals\n            )\n    \n    fig.update_layout(\n        height=700,\n        width=950,\n        margin=dict(l=80, r=40, t=35, b=80),\n        template=\"plotly_white\",\n        legend=dict(orientation=\"h\", y=-0.15, title=\"\"),\n        hovermode=\"closest\",  # Remove the moving vertical line\n        title_x=0.5,  # Center the title\n        plot_bgcolor=\"white\",\n        paper_bgcolor=\"white\"\n    )\n    \n    return self._plot_line_graph_part3(fig, subset, selected_metrics, selected_loggers)\n\nLoggerDataViewer._plot_line_graph_part2 = _plot_line_graph_part2",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "02bc2nqqkple",
   "source": "# Line graph plotting method (Part 3: legend, threshold, and season lines)\ndef _plot_line_graph_part3(self, fig, subset, selected_metrics, selected_loggers):\n    \"\"\"Add legend ordering, threshold line, and season lines.\"\"\"\n    \n    # Force legend order by reordering traces\n    desired_order = [self.logger_display_names[logger_id] for logger_id in self.unique_loggers if logger_id in selected_loggers]\n    \n    # Get current traces and reorder them\n    current_traces = list(fig.data)\n    reordered_traces = []\n    \n    # Add traces in desired order (group by legendgroup/logger)\n    for desired_name in desired_order:\n        for trace in current_traces:\n            if (hasattr(trace, 'legendgroup') and trace.legendgroup == desired_name) or \\\n               (hasattr(trace, 'name') and trace.name == desired_name):\n                if trace not in reordered_traces:\n                    reordered_traces.append(trace)\n    \n    # Add any remaining traces (like threshold line, season lines)\n    for trace in current_traces:\n        if trace not in reordered_traces:\n            reordered_traces.append(trace)\n    \n    # Update figure with reordered traces\n    self._debug_log(f\"Reordered {len(reordered_traces)} traces\")\n    fig.data = reordered_traces\n    \n    # Add 32\u00b0C threshold line if enabled (after main traces so it appears on top)\n    if self.threshold_checkbox.value:\n        # Create multiple points along the line for better hover coverage\n        x_points = pd.date_range(subset.index.min(), subset.index.max(), periods=100).floor('s')\n        y_points = [32] * len(x_points)\n        fig.add_scatter(\n            x=x_points,\n            y=y_points,\n            mode='lines',\n            line=dict(color=\"green\", width=2, dash=\"solid\"),\n            name=\"32\u00b0C Threshold\",\n            hovertemplate=\"32\u00b0C Threshold<br>%{x|%d/%m/%Y %H:%M}<br>Temperature: 32.00\u00b0C<extra></extra>\",\n            showlegend=True\n        )\n    \n    # Add season rectangles with labels if enabled (after main traces so they appear on top)\n    if self.season_lines_checkbox.value:\n        start_date = subset.index.min()\n        end_date = subset.index.max()\n        season_lines = get_season_lines(start_date, end_date)\n        \n        if len(season_lines) > 0:\n            y_max = subset[selected_metrics].max().max()\n            y_min = subset[selected_metrics].min().min()\n            \n            # Calculate periods and check for overlaps\n            periods = []\n            centers = []\n            for i in range(len(season_lines)):\n                sdate = season_lines[i][0].tz_convert(None).to_pydatetime()\n                if i < len(season_lines) - 1:\n                    next_sdate = season_lines[i + 1][0].tz_convert(None).to_pydatetime()\n                else:\n                    next_sdate = end_date.tz_convert(None).to_pydatetime()\n                period_days = (next_sdate - sdate).days\n                periods.append(period_days)\n                centers.append(sdate + (next_sdate - sdate) / 2)\n            \n            # Check if labels would overlap based on time range and label count\n            total_time_span = (end_date - start_date).days\n            num_labels = len(season_lines)\n            \n            # More sophisticated overlap detection\n            if num_labels == 0:\n                show_labels_directly = True\n            elif total_time_span > 365:  # More than a year\n                show_labels_directly = num_labels <= 8\n            elif total_time_span > 180:  # More than 6 months\n                show_labels_directly = num_labels <= 6\n            elif total_time_span > 90:   # More than 3 months\n                show_labels_directly = num_labels <= 4\n            else:  # Less than 3 months\n                show_labels_directly = num_labels <= 3\n            \n            # Create extended season rectangles that cover full data range\n            data_start = start_date.tz_convert(None).to_pydatetime()\n            data_end = end_date.tz_convert(None).to_pydatetime()\n            \n            # Add season for the very beginning if no season line exists there\n            all_dates = [data_start] + [s[0].tz_convert(None).to_pydatetime() for s in season_lines] + [data_end]\n            all_seasons = [get_season_for_date(data_start)] + [s[1] for s in season_lines] + [get_season_for_date(data_end)]\n            \n            # Create rectangles for each period\n            for i in range(len(all_dates) - 1):\n                rect_start = all_dates[i]\n                rect_end = all_dates[i + 1]\n                season_name = all_seasons[i]\n                \n                # Add vertical lines only for actual season boundaries (not data boundaries)\n                if i > 0:  # Don't add line at very start\n                    fig.add_shape(\n                        type=\"line\",\n                        x0=rect_start, x1=rect_start,\n                        y0=y_min, y1=y_max * 1.05,\n                        line=dict(color=\"black\", width=1, dash=\"dot\"),\n                        opacity=0.7\n                    )\n                \n                # Add horizontal line at top\n                fig.add_shape(\n                    type=\"line\",\n                    x0=rect_start, x1=rect_end,\n                    y0=y_max * 1.05, y1=y_max * 1.05,\n                    line=dict(color=\"black\", width=1, dash=\"dot\")\n                )\n                \n                # Add horizontal line at bottom\n                fig.add_shape(\n                    type=\"line\",\n                    x0=rect_start, x1=rect_end,\n                    y0=y_min, y1=y_min,\n                    line=dict(color=\"black\", width=1, dash=\"dot\"),\n                    opacity=0.7\n                )\n                \n                if show_labels_directly:\n                    # Show labels directly if no overlap\n                    min_period = min(periods) if periods else 30\n                    font_size = 8 if min_period > 30 else 6\n                    fig.add_annotation(\n                        x=rect_start + (rect_end - rect_start) / 2,\n                        y=y_max * 1.08,\n                        text=season_name,\n                        showarrow=False,\n                        font=dict(size=font_size, color=\"black\"),\n                        bgcolor=\"rgba(255, 255, 255, 0.8)\",\n                        bordercolor=\"black\",\n                        borderwidth=1\n                    )\n                else:\n                    # Add small hover button in center of season box\n                    center_x = rect_start + (rect_end - rect_start) / 2\n                    fig.add_scatter(\n                        x=[center_x],\n                        y=[y_max * 1.06],\n                        mode='markers',\n                        marker=dict(\n                            size=8,\n                            color=\"rgba(100, 100, 100, 0.8)\",\n                            symbol=\"circle\",\n                            line=dict(color=\"black\", width=1)\n                        ),\n                        hovertext=season_name,\n                        hoverinfo='text',\n                        showlegend=False,\n                        name=f\"Season: {season_name}\"\n                    )\n    \n    self._debug_log(\"--- Finished _plot_line_graph() successfully ---\")\n    return fig\n\nLoggerDataViewer._plot_line_graph_part3 = _plot_line_graph_part3",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "15sy663m1v9",
   "source": "# Adaptive comfort plotting methods\ndef _get_boundary_params(self):\n    \"\"\"Return (m, c, delta) for the selected comfort model.\"\"\"\n    model = self.boundary_model.value\n    if model == \"default\":\n        return 0.31, 17.3, 3.0\n    elif model == \"rh_gt_60\":\n        return 0.53, 12.85, 2.84\n    elif model == \"rh_40_60\":\n        return 0.53, 14.16, 3.70\n    elif model == \"rh_le_40\":\n        return 0.52, 15.23, 4.40\n    elif model == \"none\":\n        return None\n    return None\n\ndef _add_comfort_band(self, fig, ac_data):\n    \"\"\"Add comfort band to the figure.\"\"\"\n    params = self._get_boundary_params()\n    if params is None:\n        return\n    \n    m, c, delta = params\n    \n    x_min = ac_data[\"external_temp\"].min()\n    x_max = ac_data[\"external_temp\"].max()\n    \n    if pd.isna(x_min) or pd.isna(x_max) or x_min == x_max:\n        return\n    \n    x_vals = np.linspace(x_min, x_max, 80)\n    y_central = m * x_vals + c\n    y_upper = y_central + delta\n    y_lower = y_central - delta\n    \n    # Store comfort boundaries for statistics calculation\n    self._comfort_boundaries = {\n        'x_vals': x_vals,\n        'y_upper': y_upper,\n        'y_lower': y_lower,\n        'm': m, 'c': c, 'delta': delta\n    }\n    \n    # Green comfort band only\n    x_band = np.concatenate([x_vals, x_vals[::-1]])\n    y_band = np.concatenate([y_lower, y_upper[::-1]])\n    fig.add_trace(\n        go.Scatter(\n            x=x_band,\n            y=y_band,\n            fill=\"toself\",\n            mode=\"lines\",\n            line=dict(width=0),\n            fillcolor=\"rgba(0, 150, 0, 0.3)\",\n            hoverinfo=\"skip\",\n            showlegend=False,\n            name=\"Comfort Zone\"\n        )\n    )\n\ndef _calculate_comfort_percentage(self, data, logger_id):\n    \"\"\"Calculate percentage of points within comfort zone for a logger.\"\"\"\n    if not hasattr(self, '_comfort_boundaries'):\n        return 0.0\n    \n    logger_data = data[data['logger_id'] == logger_id]\n    if logger_data.empty:\n        return 0.0\n    \n    boundaries = self._comfort_boundaries\n    m, c, delta = boundaries['m'], boundaries['c'], boundaries['delta']\n    \n    # Calculate comfort boundaries for each point\n    ext_temps = logger_data['external_temp'].values\n    temps = logger_data['temperature'].values\n    \n    y_upper = m * ext_temps + c + delta\n    y_lower = m * ext_temps + c - delta\n    \n    # Count points within comfort zone\n    within_comfort = (temps >= y_lower) & (temps <= y_upper)\n    percentage = (within_comfort.sum() / len(temps)) * 100\n    \n    return percentage\n\ndef _update_comfort_stats(self, ac_data, selected_room_loggers):\n    \"\"\"Update comfort statistics display.\"\"\"\n    self.comfort_stats_out.clear_output()\n    \n    with self.comfort_stats_out:\n        # Calculate percentages for each selected room\n        room_percentages = {}\n        total_points = 0\n        total_comfort_points = 0\n        \n        for logger_id in selected_room_loggers:\n            percentage = self._calculate_comfort_percentage(ac_data, logger_id)\n            room_percentages[logger_id] = percentage\n            \n            logger_data = ac_data[ac_data['logger_id'] == logger_id]\n            if not logger_data.empty:\n                total_points += len(logger_data)\n                total_comfort_points += int((percentage / 100) * len(logger_data))\n        \n        # Calculate overall percentage\n        overall_percentage = (total_comfort_points / total_points * 100) if total_points > 0 else 0\n        \n        # Create HTML display\n        html_content = f\"\"\"\n        <div style=\"display: flex; flex-wrap: wrap; gap: 5px; max-width: 380px;\">\n            <div style=\"width: 100%; text-align: center; padding: 6px; border: 2px solid #333; background-color: #f0f0f0; border-radius: 3px; margin-bottom: 5px; font-size: 12px;\">\n                <strong>Overall: {overall_percentage:.1f}%</strong>\n            </div>\n        \"\"\"\n        \n        # Add individual room boxes (up to 6, arranged in 2 rows of 3)\n        for i, logger_id in enumerate(selected_room_loggers[:6]):\n            room_name = self.logger_display_names[logger_id].split(' (')[0]  # Just room name without ID\n            percentage = room_percentages[logger_id]\n            \n            html_content += f\"\"\"\n            <div style=\"width: 90px; height: 45px; padding: 3px; border: 1px solid #666; background-color: #fff; border-radius: 3px; text-align: center; font-size: 10px; display: flex; flex-direction: column; justify-content: center;\">\n                <div style=\"font-weight: bold; line-height: 1.1; margin-bottom: 2px;\">{room_name}</div>\n                <div style=\"color: #007700; font-weight: bold; font-size: 11px;\">{percentage:.1f}%</div>\n            </div>\n            \"\"\"\n        \n        html_content += \"</div>\"\n        \n        display(widgets.HTML(html_content))\n\nLoggerDataViewer._get_boundary_params = _get_boundary_params\nLoggerDataViewer._add_comfort_band = _add_comfort_band\nLoggerDataViewer._calculate_comfort_percentage = _calculate_comfort_percentage\nLoggerDataViewer._update_comfort_stats = _update_comfort_stats",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "j6u2k2wf6d",
   "source": "# Adaptive comfort main plotting method\ndef _plot_adaptive_comfort(self):\n    \"\"\"Generate adaptive comfort scatter plot.\"\"\"\n    self._debug_log(\"--- Starting _plot_adaptive_comfort() ---\")\n    mode = self.time_mode.value\n    \n    # Get selected room loggers from checkboxes\n    selected_room_display_names = [l for l, cb in self.room_logger_checkboxes.items() if cb.value]\n    name_to_id = {v: k for k, v in self.logger_display_names.items()}\n    selected_room_loggers = [name_to_id[name] for name in selected_room_display_names if name in name_to_id]\n    \n    self._debug_log(f\"Selected room loggers: {selected_room_loggers}\")\n    \n    if not selected_room_loggers:\n        self._debug_log(\"No room loggers selected - returning None\")\n        # VERBOSE: print(\"Select at least one room logger for adaptive comfort chart.\")\n        return None\n    \n    # Create time mask for selected room loggers + external logger (if exists)\n    loggers_for_mask = selected_room_loggers[:]\n    if self.external_logger:\n        loggers_for_mask.append(self.external_logger)\n    \n    selectors = {\n        \"selected_loggers\": loggers_for_mask,\n        \"between_box\": self.between_box,\n        \"year_select\": self.year_select,\n        \"month_select\": self.month_select,\n        \"week_select\": self.week_select,\n        \"day_select\": self.day_select\n    }\n    \n    mask = get_time_mask(self.df, mode, selectors)\n    \n    # Prepare adaptive comfort data\n    ac_data = prepare_adaptive_comfort_data(self.df, mask, self.external_logger, self.room_loggers)\n    \n    self._debug_log(f\"Adaptive comfort data shape: {ac_data.shape}\")\n    \n    if ac_data.empty:\n        self._debug_log(\"No adaptive comfort data available - returning None\")\n        # VERBOSE: print(\"No data available for adaptive comfort chart in selected time range.\")\n        return None\n    \n    # Filter for only selected room loggers\n    ac_data = ac_data[ac_data[\"logger_id\"].isin(selected_room_loggers)].copy()\n    \n    self._debug_log(f\"Filtered adaptive comfort data shape: {ac_data.shape}\")\n    \n    if ac_data.empty:\n        self._debug_log(\"No data for selected room loggers - returning None\")\n        # VERBOSE: print(\"No data available for selected room loggers in the time range.\")\n        return None\n    \n    # Add datetime column for hover\n    ac_data[\"datetime\"] = ac_data.index\n    \n    # Map logger IDs to display names\n    ac_data[\"logger_display\"] = ac_data[\"logger_id\"].map(self.logger_display_names)\n    \n    # Create title with credit if using Vellei et al. models\n    title = f\"<b>Adaptive Comfort Chart \u2013 {mode}</b>\"\n    if self.boundary_model.value in [\"rh_gt_60\", \"rh_40_60\", \"rh_le_40\"]:\n        title += \"<br><span style='font-size:12px; line-height:0.8'>Boundary source: Vellei et al.</span>\"\n    \n    # Create scatter plot\n    fig = px.scatter(\n        ac_data,\n        x=\"external_temp\",\n        y=\"temperature\",\n        color=\"logger_display\",\n        title=title,\n        labels={\n            \"external_temp\": \"Running mean external temperature (\u00b0C)\",\n            \"temperature\": \"Air temperature (approximation of operative temperature)\",\n            \"logger_display\": \"Room logger\",\n            \"datetime\": \"Date/time\"\n        },\n        color_discrete_map={self.logger_display_names[k]: v for k, v in self.colour_map.items()},\n        opacity=0.6,\n        hover_data={\"datetime\": \"|%d/%m/%Y %H:%M\"},\n        category_orders={\"logger_display\": [self.logger_display_names[logger_id] for logger_id in selected_room_loggers]}\n    )\n    \n    fig.update_layout(\n        height=700,\n        width=950,\n        margin=dict(l=80, r=40, t=25, b=80),\n        template=\"plotly_white\",\n        legend=dict(orientation=\"h\", y=-0.15, title=\"\"),\n        hovermode=\"closest\",\n        title_x=0.5,  # Center the title\n        plot_bgcolor=\"white\",\n        paper_bgcolor=\"white\"\n    )\n    \n    # Force legend order for adaptive comfort by reordering traces\n    room_loggers_in_data = [logger_id for logger_id in selected_room_loggers if logger_id in ac_data[\"logger_id\"].unique()]\n    desired_order = [self.logger_display_names[logger_id] for logger_id in room_loggers_in_data]\n    \n    # Get current traces and reorder them\n    current_traces = list(fig.data)\n    reordered_traces = []\n    \n    # Add traces in desired order\n    for desired_name in desired_order:\n        for trace in current_traces:\n            if hasattr(trace, 'name') and trace.name == desired_name:\n                reordered_traces.append(trace)\n                break\n    \n    # Add any remaining traces (like comfort band)\n    for trace in current_traces:\n        if trace not in reordered_traces:\n            reordered_traces.append(trace)\n    \n    # Update figure with reordered traces\n    fig.data = reordered_traces\n    \n    fig.update_traces(marker=dict(size=3), opacity=0.85)\n    \n    # Add comfort band and above/below shading if selected\n    if self.boundary_model.value != \"none\":\n        self._add_comfort_band(fig, ac_data)\n        self._update_comfort_stats(ac_data, selected_room_loggers)\n    else:\n        self.comfort_stats_out.clear_output()\n    \n    self._debug_log(\"--- Finished _plot_adaptive_comfort() successfully ---\")\n    return fig\n\nLoggerDataViewer._plot_adaptive_comfort = _plot_adaptive_comfort",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "l4ebx0dd9y9",
   "source": "# Download methods (Part 1: simple chart download)\ndef _download_chart(self, button):\n    \"\"\"Download the current chart as an image.\"\"\"\n    if hasattr(self, 'current_fig') and self.current_fig is not None:\n        try:\n            # Create images folder if it doesn't exist\n            import os\n            images_dir = Path(\"images\")\n            images_dir.mkdir(exist_ok=True)\n            \n            # Create a filename with timestamp\n            timestamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            filename = images_dir / f\"omnisense_chart_{timestamp}.png\"\n            \n            # Create a copy of the figure with extra top margin for white space\n            fig_copy = go.Figure(self.current_fig)\n            current_margin = fig_copy.layout.margin\n            fig_copy.update_layout(\n                margin=dict(\n                    l=current_margin.l,\n                    r=current_margin.r,\n                    t=current_margin.t + 40,  # Add 40px white space above title\n                    b=current_margin.b\n                )\n            )\n            \n            # Download the figure\n            fig_copy.write_image(filename, width=1200, height=840, scale=2)\n            # VERBOSE: print(f\"Chart saved as {filename.absolute()}\")\n        except Exception as e:\n            pass\n            # VERBOSE: print(f\"Error saving chart: {e}\")\n            # VERBOSE: print(\"Make sure kaleido is installed: pip install kaleido\")\n    else:\n        pass\n        # VERBOSE: print(\"No chart to download. Please generate a chart first.\")\n\nLoggerDataViewer._download_chart = _download_chart",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "nl0jlfr9h",
   "source": [
    "# Download with statistics and display methods\n",
    "def _download_chart_with_stats(self, button):\n",
    "    \"\"\"Download the adaptive comfort chart with statistics boxes.\"\"\"\n",
    "    if hasattr(self, 'current_fig') and self.current_fig is not None and self.chart_type.value == \"Adaptive Comfort\":\n",
    "        try:\n",
    "            # Create images folder if it doesn't exist\n",
    "            import os\n",
    "            images_dir = Path(\"images\")\n",
    "            images_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Create a filename with timestamp\n",
    "            timestamp = dt.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = images_dir / f\"omnisense_adaptive_with_stats_{timestamp}.png\"\n",
    "            \n",
    "            # Create a combined image using matplotlib\n",
    "            import matplotlib.pyplot as plt\n",
    "            import matplotlib.patches as patches\n",
    "            from matplotlib.patches import FancyBboxPatch\n",
    "            import io\n",
    "            from PIL import Image\n",
    "            \n",
    "            # Export the plotly figure to image bytes\n",
    "            fig_bytes = self.current_fig.to_image(format=\"png\", width=1200, height=700, scale=2)\n",
    "            chart_img = Image.open(io.BytesIO(fig_bytes))\n",
    "            \n",
    "            # Create matplotlib figure for combined layout\n",
    "            fig, (ax_stats, ax_chart) = plt.subplots(2, 1, figsize=(15, 12), \n",
    "                                                    gridspec_kw={'height_ratios': [1, 4], 'hspace': 0.05})\n",
    "            \n",
    "            # Hide axes\n",
    "            ax_stats.axis('off')\n",
    "            ax_chart.axis('off')\n",
    "            \n",
    "            # Add white space at top\n",
    "            fig.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95)\n",
    "            \n",
    "            # Get comfort statistics data\n",
    "            if hasattr(self, '_comfort_boundaries'):\n",
    "                selected_room_display_names = [l for l, cb in self.room_logger_checkboxes.items() if cb.value]\n",
    "                name_to_id = {v: k for k, v in self.logger_display_names.items()}\n",
    "                selected_room_loggers = [name_to_id[name] for name in selected_room_display_names if name in name_to_id]\n",
    "                \n",
    "                # Calculate statistics (reuse existing logic)\n",
    "                loggers_for_mask = selected_room_loggers[:]\n",
    "                if self.external_logger:\n",
    "                    loggers_for_mask.append(self.external_logger)\n",
    "                \n",
    "                selectors = {\n",
    "                    \"selected_loggers\": loggers_for_mask,\n",
    "                    \"between_box\": self.between_box,\n",
    "                    \"year_select\": self.year_select,\n",
    "                    \"month_select\": self.month_select,\n",
    "                    \"week_select\": self.week_select,\n",
    "                    \"day_select\": self.day_select\n",
    "                }\n",
    "                mask = get_time_mask(self.df, self.time_mode.value, selectors)\n",
    "                ac_data = prepare_adaptive_comfort_data(self.df, mask, self.external_logger, self.room_loggers)\n",
    "                ac_data = ac_data[ac_data[\"logger_id\"].isin(selected_room_loggers)].copy()\n",
    "                \n",
    "                # Calculate percentages\n",
    "                room_percentages = {}\n",
    "                total_points = 0\n",
    "                total_comfort_points = 0\n",
    "                \n",
    "                for logger_id in selected_room_loggers:\n",
    "                    percentage = self._calculate_comfort_percentage(ac_data, logger_id)\n",
    "                    room_percentages[logger_id] = percentage\n",
    "                    \n",
    "                    logger_data = ac_data[ac_data['logger_id'] == logger_id]\n",
    "                    if not logger_data.empty:\n",
    "                        total_points += len(logger_data)\n",
    "                        total_comfort_points += int((percentage / 100) * len(logger_data))\n",
    "                \n",
    "                overall_percentage = (total_comfort_points / total_points * 100) if total_points > 0 else 0\n",
    "                \n",
    "                # Draw statistics boxes\n",
    "                ax_stats.text(0.5, 0.8, \"Comfort Statistics\", ha='center', va='center', \n",
    "                            fontsize=16, fontweight='bold', transform=ax_stats.transAxes)\n",
    "                \n",
    "                # Overall box\n",
    "                overall_box = FancyBboxPatch((0.35, 0.5), 0.3, 0.15, \n",
    "                                           boxstyle=\"round,pad=0.01\", \n",
    "                                           facecolor='#f0f0f0', edgecolor='black', linewidth=2)\n",
    "                ax_stats.add_patch(overall_box)\n",
    "                ax_stats.text(0.5, 0.575, f\"Overall: {overall_percentage:.1f}%\", \n",
    "                            ha='center', va='center', fontsize=12, fontweight='bold',\n",
    "                            transform=ax_stats.transAxes)\n",
    "                \n",
    "                # Individual room boxes\n",
    "                box_width = 0.12\n",
    "                box_height = 0.12\n",
    "                start_x = 0.1\n",
    "                y_pos = 0.25\n",
    "                \n",
    "                for i, logger_id in enumerate(selected_room_loggers[:6]):\n",
    "                    x_pos = start_x + (i % 3) * (box_width + 0.05)\n",
    "                    if i >= 3:\n",
    "                        y_pos = 0.1\n",
    "                        x_pos = start_x + ((i - 3) % 3) * (box_width + 0.05)\n",
    "                    \n",
    "                    room_name = self.logger_display_names[logger_id].split(' (')[0]\n",
    "                    percentage = room_percentages[logger_id]\n",
    "                    \n",
    "                    room_box = FancyBboxPatch((x_pos, y_pos), box_width, box_height,\n",
    "                                            boxstyle=\"round,pad=0.005\",\n",
    "                                            facecolor='white', edgecolor='#666', linewidth=1)\n",
    "                    ax_stats.add_patch(room_box)\n",
    "                    \n",
    "                    ax_stats.text(x_pos + box_width/2, y_pos + box_height*0.7, room_name,\n",
    "                                ha='center', va='center', fontsize=9, fontweight='bold',\n",
    "                                transform=ax_stats.transAxes)\n",
    "                    ax_stats.text(x_pos + box_width/2, y_pos + box_height*0.3, f\"{percentage:.1f}%\",\n",
    "                                ha='center', va='center', fontsize=10, fontweight='bold', color='#007700',\n",
    "                                transform=ax_stats.transAxes)\n",
    "            \n",
    "            # Add the chart image\n",
    "            ax_chart.imshow(chart_img)\n",
    "            \n",
    "            # Save the combined figure\n",
    "            plt.savefig(filename, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "            plt.close()\n",
    "            \n",
    "            # VERBOSE: print(f\"Chart with statistics saved as {filename.absolute()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # VERBOSE: print(f\"Error saving chart with statistics: {e}\")\n",
    "            # VERBOSE: print(\"Make sure kaleido, matplotlib, and PIL are installed\")\n",
    "    else:\n",
    "        pass\n",
    "        # VERBOSE: print(\"No adaptive comfort chart to download. Please generate an adaptive comfort chart first.\")\n",
    "\n",
    "def display_viewer(self):\n",
    "    \"\"\"Display the viewer interface.\"\"\"\n",
    "    # Use module-level reference to avoid import issues in Voil\u00e0\n",
    "    self._debug_log(\"Initializing viewer interface...\")\n",
    "    _ipython_display(self.time_controls, self.controls, self.plot_out)\n",
    "    self._debug_log(\"Interface displayed, updating initial plot...\")\n",
    "    self.update_plot()\n",
    "    self._debug_log(\"Initial setup complete!\")\n",
    "\n",
    "LoggerDataViewer._download_chart_with_stats = _download_chart_with_stats\n",
    "LoggerDataViewer.display = display_viewer"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa46d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 Omnisense CSV file(s) in data/omnisense\n",
      "\n",
      "Processing 070226.csv...\n",
      "Loaded 2501 records from: House 5, Kitchen\n",
      "Loaded 2416 records from: House 5, Bed 4\n",
      "Loaded 2498 records from: House 5, Bed 4, above ceiling\n",
      "Loaded 2500 records from: House 5, Bed 2\n",
      "Loaded 2499 records from: House 5, Living Room\n",
      "Loaded 2498 records from: House 5, Mother's Bedroom\n",
      "Loaded 2499 records from: House 5, Washrooms area\n",
      "Loaded 2500 records from: House 3, Bed 2\n",
      "Loaded 2498 records from: House 5, Bed 3\n",
      "Skipping Sun, Wind, Rain weather station gateway (in external box) (no temperature/humidity data)\n",
      "Skipping Weather Station, T & RH (weather station)\n",
      "Loaded 4583 records from: House 5, Metal Roof, above Bed 4\n",
      "Skipping Performance stats (no temperature/humidity data)\n",
      "\n",
      "Loading external temperature data...\n",
      "Loaded 504 external temperature records from Open-Meteo\n",
      "  Date range: 2026-01-17 00:00:00 to 2026-02-06 23:00:00\n",
      "\n",
      "Total datasets loaded: 2\n",
      "Total records: 27496\n",
      "Unique loggers: 11\n",
      "Logger IDs: ['External (Open-Meteo)', 'House 3, Bed 2', 'House 5, Bed 2', 'House 5, Bed 3', 'House 5, Bed 4', 'House 5, Bed 4, above ceiling', 'House 5, Kitchen', 'House 5, Living Room', 'House 5, Metal Roof, above Bed 4', \"House 5, Mother's Bedroom\", 'House 5, Washrooms area']\n",
      "Found loggers: ['External (Open-Meteo)', 'House 3, Bed 2', 'House 5, Bed 2', 'House 5, Bed 3', 'House 5, Bed 4', 'House 5, Bed 4, above ceiling', 'House 5, Kitchen', 'House 5, Living Room', 'House 5, Metal Roof, above Bed 4', \"House 5, Mother's Bedroom\", 'House 5, Washrooms area']\n",
      "External logger: External (Open-Meteo)\n",
      "Room loggers: ['House 3, Bed 2', 'House 5, Bed 2', 'House 5, Bed 3', 'House 5, Bed 4', 'House 5, Bed 4, above ceiling', 'House 5, Kitchen', 'House 5, Living Room', 'House 5, Metal Roof, above Bed 4', \"House 5, Mother's Bedroom\", 'House 5, Washrooms area']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f41eae0c68469795612d3e61eaa29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Chart Type:', layout=Layout(width='200px'), options=('Line Graph', 'Adapt\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2636f267864dfd95740483aa83bf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<b>Loggers</b>'), Checkbox(value=True, description='External Tempera\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb1e120b6984dadafd08c5d1ddc306d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "viewer = LoggerDataViewer()\n",
    "viewer.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of EN15251 running mean calculation working correctly:\n",
    "# \n",
    "# Sample data from external logger (861011) for first few days:\n",
    "# Day 1: 25.5\u00b0C daily mean -> Trm[0] = 25.5\u00b0C (seed value)\n",
    "# Day 2: 26.2\u00b0C daily mean -> Trm[1] = (1-0.8)*26.2 + 0.8*25.5 = 0.2*26.2 + 0.8*25.5 = 5.24 + 20.4 = 25.64\u00b0C\n",
    "# Day 3: 24.8\u00b0C daily mean -> Trm[2] = (1-0.8)*24.8 + 0.8*25.64 = 0.2*24.8 + 0.8*25.64 = 4.96 + 20.512 = 25.472\u00b0C\n",
    "# Day 4: 27.1\u00b0C daily mean -> Trm[3] = (1-0.8)*27.1 + 0.8*25.472 = 0.2*27.1 + 0.8*25.472 = 5.42 + 20.3776 = 25.7976\u00b0C\n",
    "#\n",
    "# This exponential weighting gives more influence to recent temperatures while maintaining\n",
    "# a smooth running average that responds gradually to temperature changes, as required by EN15251."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
